{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2018BTECS00033_Assignment8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acem-_-G7Bn2"
      },
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PuGlwb57yIJ"
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lQxRRiL9Nxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9529f9c-5d9d-4ed3-dd67-8ccd7d314fbd"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Wed_Apr_11_23:16:29_CDT_2018\n",
            "Cuda compilation tools, release 9.2, V9.2.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOcPMA0F9Src",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acbe8446-0318-4ed0-99af-54e3e59e400e"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-t4p8gmm_\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-t4p8gmm_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swHrydoG9XLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1a9937-d352-488b-b9d9-9ec08f5ebdd8"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW73xV2F9bVI"
      },
      "source": [
        "%%writefile matMul.cu\n",
        "#include<stdio.h>\n",
        "#include<cuda.h>\n",
        "#define row1 2 /* Number of rows of first matrix */\n",
        "#define col1 3 /* Number of columns of first matrix */\n",
        "#define row2 3 /* Number of rows of second matrix */\n",
        "#define col2 2 /* Number of columns of second matrix */\n",
        "__global__ void matproduct(int *l,int *m, int *n)\n",
        "{\n",
        "\tint x=blockIdx.x;\n",
        "\tint y=blockIdx.y;\n",
        "\tint k;\n",
        "\tn[col2*y+x]=0;\n",
        "\tfor(k=0;k<col1;k++)\n",
        "\t{\n",
        "\t\tn[col2*y+x]=n[col2*y+x]+l[col1*y+k]*m[col2*k+x];\n",
        "\t} \n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tint a[row1][col1]={{1,2,3},{1,2,3}};\n",
        "\tint b[row2][col2]={{1,2},{3,4},{5,6}};\n",
        "\tint c[row1][col2];\n",
        "\tint *d,*e,*f;\n",
        "\tint i,j;\n",
        "\n",
        "\tcudaMalloc((void **)&d,row1*col1*sizeof(int));\n",
        "\tcudaMalloc((void **)&e,row2*col2*sizeof(int));\n",
        "\tcudaMalloc((void **)&f,row1*col2*sizeof(int));\n",
        "\tcudaMemcpy(d,a,row1*col1*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(e,b,row2*col2*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\tdim3 grid(col2,row1);\n",
        "\n",
        "\t/* Here we are defining two dimensional Grid(collection of blocks) structure. Syntax is\n",
        "\tdim3 grid(no. of columns,no. of rows) */\n",
        "\t\n",
        "\tmatproduct<<<grid,1>>>(d,e,f);\n",
        "\tcudaMemcpy(c,f,row1*col2*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\tprintf(\"\\nProduct of two matrices:\\n\");\n",
        "\tfor(i=0;i<row1;i++)\n",
        "\t{\n",
        "\t\tfor(j=0;j<col2;j++)\n",
        "\t\t{\n",
        "\t\t\tprintf(\"%d\\t\",c[i][j]);\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\tcudaFree(d);\n",
        "\tcudaFree(e);\n",
        "\tcudaFree(f);\n",
        "\treturn 0; \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aAofBJ9fHnC"
      },
      "source": [
        "!nvcc -o multiply matMul.cu"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY8JCjLqnZa9",
        "outputId": "c395a94a-3f3c-40fc-fad9-6566470cd4a4"
      },
      "source": [
        "! ./multiply"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Product of two matrices:\n",
            "22\t28\t\n",
            "22\t28\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUPWTraZphLY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyfEo7iMph5j"
      },
      "source": [
        "!nvprof ./multiply"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GJs8ROzrQEs",
        "outputId": "cd815d54-1fca-4054-f382-c5280026993c"
      },
      "source": [
        "%%writefile optimize.cu\n",
        "#include<stdio.h>\n",
        "#include<cuda.h>\n",
        "#define row1 2 \n",
        "#define col1 3 \n",
        "#define row2 3 \n",
        "#define col2 2 \n",
        "\n",
        "__global__ void matproductsharedmemory(int *l,int *m, int *n)\n",
        "{\n",
        "    int x=blockIdx.x;\n",
        "    int y=blockIdx.y;\n",
        "    __shared__ int p[col1];\n",
        "\n",
        "    int i;\n",
        "    int k=threadIdx.x;\n",
        "\n",
        "    n[col2*y+x]=0;\n",
        "\n",
        "   p[k]=l[col1*y+k]*m[col2*k+x];\n",
        "\n",
        "  __syncthreads();\n",
        " for(i=0;i<col1;i++)\n",
        "  n[col2*y+x]=n[col2*y+x]+p[i];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int a[row1][col1]={{1,2,3},{4,5,6}};\n",
        "    int b[row2][col2]={{1,2},{3,4},{5,6}};;\n",
        "    int c[row1][col2];\n",
        "    int *d,*e,*f;\n",
        "    int i,j;\n",
        "\n",
        "   cudaMalloc((void **)&d,row1*col1*sizeof(int));\n",
        "    cudaMalloc((void **)&e,row2*col2*sizeof(int));\n",
        "    cudaMalloc((void **)&f,row1*col2*sizeof(int));\n",
        "\n",
        " cudaMemcpy(d,a,row1*col1*sizeof(int),cudaMemcpyHostToDevice);\n",
        " cudaMemcpy(e,b,row2*col2*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\n",
        "dim3 grid(col2,row1);\n",
        "\n",
        "matproductsharedmemory<<<grid,col1>>>(d,e,f);\n",
        "\n",
        " cudaMemcpy(c,f,row1*col2*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\n",
        " printf(\"\\n Product of two matrices:\\n \");\n",
        "    for(i=0;i<row1;i++)\n",
        "    {\n",
        "        for(j=0;j<col2;j++)\n",
        "        {\n",
        "              printf(\"%d\\t\",c[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    cudaFree(d);\n",
        "    cudaFree(e);\n",
        "    cudaFree(f);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting optimize.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzYJd01Ow3HX"
      },
      "source": [
        "!nvcc -o opt optimize.cu"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI5Pz3yr2plQ",
        "outputId": "6eb1aaf0-1708-48cc-cb5f-372545b1a46c"
      },
      "source": [
        "! ./opt"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Product of two matrices:\n",
            " 22\t28\t\n",
            "49\t64\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnQDFiIm2zBS",
        "outputId": "185e1ddb-3faf-4e1b-a7b8-5c44da058325"
      },
      "source": [
        "!nvprof --print-gpu-trace ./opt"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==34563== NVPROF is profiling process 34563, command: ./opt\n",
            "==34563== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version \n",
            "\n",
            " Product of two matrices:\n",
            " 22\t28\t\n",
            "49\t64\t\n",
            "==34563== Profiling application: ./opt\n",
            "==34563== Profiling result:\n",
            "   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput  SrcMemType  DstMemType           Device   Context    Stream  Name\n",
            "413.56ms  2.3360us                    -               -         -         -         -       24B  9.7980MB/s    Pageable      Device    Tesla K80 (0)         1         7  [CUDA memcpy HtoD]\n",
            "413.58ms  1.5360us                    -               -         -         -         -       24B  14.901MB/s    Pageable      Device    Tesla K80 (0)         1         7  [CUDA memcpy HtoD]\n",
            "413.80ms  4.5120us              (2 2 1)         (3 1 1)        14       12B        0B         -           -           -           -    Tesla K80 (0)         1         7  matproductsharedmemory(int*, int*, int*) [110]\n",
            "413.81ms  2.3680us                    -               -         -         -         -       16B  6.4437MB/s      Device    Pageable    Tesla K80 (0)         1         7  [CUDA memcpy DtoH]\n",
            "\n",
            "Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.\n",
            "SSMem: Static shared memory allocated per CUDA block.\n",
            "DSMem: Dynamic shared memory allocated per CUDA block.\n",
            "SrcMemType: The type of source memory accessed by memory operation/copy\n",
            "DstMemType: The type of destination memory accessed by memory operation/copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J8Q2yEb3fbu",
        "outputId": "31cd0bf0-6ebd-4787-eb7a-03473bf122b5"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#include<cuda.h>\n",
        "__global__ void arradd(int *x,int *y, int *z)\n",
        "{\n",
        "int id=blockIdx.x;\n",
        "z[id]=x[id]+y[id];\n",
        "}\n",
        "int main()\n",
        "{\n",
        "int a[6];\n",
        "int b[6];\n",
        "int c[6];\n",
        "int *d,*e,*f;\n",
        "int i;\n",
        " printf(\"Program for Private Memory\");\n",
        "printf(\"\\n elements of first array: \");\n",
        "for(i=0;i<6;i++)\n",
        "{\n",
        "a[i]=i;\n",
        "printf(\"%d \",a[i]);\n",
        "}\n",
        "printf(\"\\n elements of second array: \");\n",
        "for(i=0;i<6;i++)\n",
        "{\n",
        "b[i]=i;\n",
        "printf(\"%d \",b[i]);\n",
        "}\n",
        "cudaMalloc((void **)&d,6*sizeof(int));\n",
        "cudaMalloc((void **)&e,6*sizeof(int));\n",
        "cudaMalloc((void **)&f,6*sizeof(int));\n",
        "cudaMemcpy(d,a,6*sizeof(int),cudaMemcpyHostToDevice);\n",
        "cudaMemcpy(e,b,6*sizeof(int),cudaMemcpyHostToDevice);\n",
        "arradd<<<6,1>>>(d,e,f);\n",
        "cudaMemcpy(c,f,6*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "printf(\"\\nSum of two arrays:\\n \");\n",
        "for(i=0;i<6;i++)\n",
        "{\n",
        "printf(\"%d\\t\",c[i]);\n",
        "}\n",
        "cudaFree(d);\n",
        "cudaFree(e);\n",
        "cudaFree(f);\n",
        "return 0;\n",
        "}"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Program for Private Memory\n",
            " elements of first array: 0 1 2 3 4 5 \n",
            " elements of second array: 0 1 2 3 4 5 \n",
            "Sum of two arrays:\n",
            " 0\t2\t4\t6\t8\t10\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F1V4HJH_rrH",
        "outputId": "1f37641b-ad8e-4e79-bb0a-72f4724acb35"
      },
      "source": [
        "%%cu\n",
        "#include<iostream>\n",
        "#include<cuda.h>\n",
        "__managed__ int x[10];\n",
        "__global__ void GPU_func( )\n",
        "{\n",
        "for (int i = 0; i < 10; i++ )\n",
        "{\n",
        "printf(\"%d \", x[i]);\n",
        "x[i] = x[i] + i;\n",
        "}\n",
        "printf(\"\\n\");\n",
        "}\n",
        "int main()\n",
        "{\n",
        "for (int i = 0; i < 10; i++ )\n",
        "x[i] = i;\n",
        "GPU_func<<< 1, 1 >>>( );\n",
        "cudaDeviceSynchronize();\n",
        "for (int i = 0; i < 10; i++ )\n",
        "{\n",
        "printf(\"%d \", x[i]);\n",
        "}\n",
        "printf(\"\\n\");\n",
        "return 0;\n",
        "}"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1 2 3 4 5 6 7 8 9 \n",
            "0 2 4 6 8 10 12 14 16 18 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWae8JcKJpVE",
        "outputId": "05393623-2926-425e-b374-118a11e7cbcf"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#include<cuda.h>\n",
        "#define row1 2 \n",
        "#define col1 3 \n",
        "#define row2 3 \n",
        "#define col2 2 \n",
        "\n",
        "__global__ void matproductsharedmemory(int *l,int *m, int *n)\n",
        "{\n",
        "    int x=blockIdx.x;\n",
        "    int y=blockIdx.y;\n",
        "    __shared__ int p[col1];\n",
        "\n",
        "    int i;\n",
        "    int k=threadIdx.x;\n",
        "\n",
        "    n[col2*y+x]=0;\n",
        "\n",
        "   p[k]=l[col1*y+k]*m[col2*k+x];\n",
        "\n",
        "  __syncthreads();\n",
        " for(i=0;i<col1;i++)\n",
        "  n[col2*y+x]=n[col2*y+x]+p[i];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    printf(\"Program demonstrating shared memory\\n\");\n",
        "    int a[row1][col1]={{1,2,3},{4,5,6}};\n",
        "    int b[row2][col2]={{1,2},{3,4},{5,6}};;\n",
        "    int c[row1][col2];\n",
        "    int *d,*e,*f;\n",
        "    int i,j;\n",
        "\n",
        "   cudaMalloc((void **)&d,row1*col1*sizeof(int));\n",
        "    cudaMalloc((void **)&e,row2*col2*sizeof(int));\n",
        "    cudaMalloc((void **)&f,row1*col2*sizeof(int));\n",
        "\n",
        " cudaMemcpy(d,a,row1*col1*sizeof(int),cudaMemcpyHostToDevice);\n",
        " cudaMemcpy(e,b,row2*col2*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\n",
        "dim3 grid(col2,row1);\n",
        "\n",
        "matproductsharedmemory<<<grid,col1>>>(d,e,f);\n",
        "\n",
        " cudaMemcpy(c,f,row1*col2*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\n",
        " printf(\"\\n Product of two matrices:\\n \");\n",
        "    for(i=0;i<row1;i++)\n",
        "    {\n",
        "        for(j=0;j<col2;j++)\n",
        "        {\n",
        "              printf(\"%d\\t\",c[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    cudaFree(d);\n",
        "    cudaFree(e);\n",
        "    cudaFree(f);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Program demonstrating shared memory\n",
            "\n",
            " Product of two matrices:\n",
            " 22\t28\t\n",
            "49\t64\t\n",
            "\n"
          ]
        }
      ]
    }
  ]
}